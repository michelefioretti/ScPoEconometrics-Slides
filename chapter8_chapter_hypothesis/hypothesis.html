<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Applied Data Analysis for Public Policy Studies</title>
    <meta charset="utf-8" />
    <meta name="author" content="Michele Fioretti" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <script src="https://use.fontawesome.com/5235085b15.js"></script>
    <link rel="stylesheet" href="../css/scpo.css" type="text/css" />
    <link rel="stylesheet" href="../css/scpo-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Applied Data Analysis for Public Policy Studies
## Hypothesis Testing
### Michele Fioretti
### SciencesPo Paris </br> 2020-08-11

---


layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---



layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---

# Packages used in this set of slides


```r
library(tidyverse)
library(infer)
library(moderndive)
```

---

# Is There Gender Discrimination In Promotions?

&lt;!-- also: https://www.ncbi.nlm.nih.gov/pubmed/12083361 --&gt;

.pull-left[
* [An article](http://fcrstemalgebra1.pbworks.com/w/file/fetch/82019231/1e.%20Sex%20role%20stereotypes.pdf) published in the *Journal of Applied Psychology* in 1974 investigates whether female employees at Banks are discriminated against.

* 48 supervisors were given *identical* candidate CVs - identical up to the first name, which was male or female.

* Many similar experiments have been conducted with other groups. Arabic Names, Black names, Jewish names or other groups that can be identified from typical name choice. [[1]](https://catalogue-bibliotheque.sciencespo.fr/discovery/fulldisplay?docid=cdi_proquest_journals_233023724&amp;context=PC&amp;vid=33USPC_SPO:SPO&amp;lang=fr&amp;search_scope=MyInst_and_CI&amp;adaptor=Primo%20Central&amp;tab=Everything&amp;query=any,contains,Are%20Emily%20and%20Greg%20More%20Employable%20Than%20Lakisha%20and%20Jamal%3F%20A%20Field%20Experiment%20on%20Labor%20Market%20Discrimination&amp;offset=0),
[[2]](https://catalogue-bibliotheque.sciencespo.fr/discovery/search?query=any,contains,Do%20health%20plans%20risk-select%3F%20An%20audit%20study%20on%20Germany%27s%20Social%20Health%20Insurance☆&amp;tab=Everything&amp;search_scope=MyInst_and_CI&amp;vid=33USPC_SPO:SPO&amp;lang=fr&amp;offset=0),
[[3]](https://www.nytimes.com/2019/12/06/business/algorithm-bias-fix.html), ...
]

--

.pull-right[


```r
library(moderndive)
promotions
```

```
## # A tibble: 48 x 3
##       id decision gender
##    &lt;int&gt; &lt;fct&gt;    &lt;fct&gt; 
##  1     1 promoted male  
##  2     2 promoted male  
##  3     3 promoted male  
##  4     4 promoted male  
##  5     5 promoted male  
##  6     6 promoted male  
##  7     7 promoted male  
##  8     8 promoted male  
##  9     9 promoted male  
## 10    10 promoted male  
## # … with 38 more rows
```

```r
# for info on the `dataset`
?promotions 
# Data from a 1970's study on whether gender 
# influences hiring recommendations [...]
```
]

---

# Looking At Promotions

.pull-left[
&lt;img src="hypothesis_files/figure-html/unnamed-chunk-3-1.svg" style="display: block; margin: auto;" /&gt;
]

.pull-right[

```r
promotions %&gt;% 
  group_by(gender, decision) %&gt;% 
  summarize(n = n()) %&gt;%
  mutate(proportion = n / sum(n))
```

```
## # A tibble: 4 x 4
## # Groups:   gender [2]
##   gender decision     n proportion
##   &lt;fct&gt;  &lt;fct&gt;    &lt;int&gt;      &lt;dbl&gt;
## 1 male   not          3      0.125
## 2 male   promoted    21      0.875
## 3 female not         10      0.417
## 4 female promoted    14      0.583
```

* 87.5% of "men" were promoted.
* 58.3% of "women" were promoted.
* That's a difference of 87.55 - 58.3% = 29.2%.
* Is the 29% advantage for men in this sample **conclusive evidence**?
* In a *hyopthetical world* **without gender discrimination**, could we have observed a 29% difference *by chance*?

]


---

# Imposing A Hypothetical World: No Gender Discriminiation

.pull-left[
* Suppose we lived in a world without gender discrimination.

* The label `gender` in our dataframe would be meaningless.

* Let's randomly reassign `gender` to each row and see how this affects the result.

* Suppose we have 48 playing cards: 24 red (female) and 24 (black)

* Shuffle the cards, and lay down the cards in a row, record `f` if **red**.
]

--

.pull-right[

```r
bind_cols(promotions, promotions_shuffled) #?promotions_shuffled for info
```

```
## # A tibble: 48 x 6
##    id...1 decision...2 gender...3 id...4 decision...5 gender...6
##     &lt;int&gt; &lt;fct&gt;        &lt;fct&gt;       &lt;int&gt; &lt;fct&gt;        &lt;fct&gt;     
##  1      1 promoted     male            1 promoted     female    
##  2      2 promoted     male            2 promoted     female    
##  3      3 promoted     male            3 promoted     male      
##  4      4 promoted     male            4 promoted     female    
##  5      5 promoted     male            5 promoted     male      
##  6      6 promoted     male            6 promoted     male      
##  7      7 promoted     male            7 promoted     male      
##  8      8 promoted     male            8 promoted     female    
##  9      9 promoted     male            9 promoted     male      
## 10     10 promoted     male           10 promoted     female    
## # … with 38 more rows
```

* Observe how in `promotions_shuffled` we randomly assigned `gender1`.

* The `decision` column is the same!

* What does this now look like?
]

---

# Reshuffled Promotions

.pull-left[
&lt;img src="hypothesis_files/figure-html/unnamed-chunk-6-1.svg" style="display: block; margin: auto;" /&gt;

]

.pull-right[

```r
promotions %&gt;% 
  group_by(gender, decision) %&gt;% 
  summarize(n = n()) %&gt;%
  mutate(proportion = n / sum(n))
```

```
## # A tibble: 4 x 4
## # Groups:   gender [2]
##   gender decision     n proportion
##   &lt;fct&gt;  &lt;fct&gt;    &lt;int&gt;      &lt;dbl&gt;
## 1 male   not          3      0.125
## 2 male   promoted    21      0.875
## 3 female not         10      0.417
## 4 female promoted    14      0.583
```


```r
promotions_shuffled %&gt;% 
  group_by(gender, decision) %&gt;% 
  summarize(n = n()) %&gt;%
  mutate(proportion = n / sum(n))
```

```
## # A tibble: 4 x 4
## # Groups:   gender [2]
##   gender decision     n proportion
##   &lt;fct&gt;  &lt;fct&gt;    &lt;int&gt;      &lt;dbl&gt;
## 1 male   not          6      0.25 
## 2 male   promoted    18      0.75 
## 3 female not          7      0.292
## 4 female promoted    17      0.708
```
]


---

# Sampling Variation?

.pull-left[
* In the hypothetical world, the difference was only 4.2%.

* But what's the role of ***sampling variation***? How representative of that hypothetical world is 4.2%?

* Let's construct the sampling distribution ourselves!
]

--

.pull-right[
1. You need to shuffle a deck of 48 cards, 24 red, 24 black, and lay out card after card in front of you.

2. You do **not** put the cards back into the deck!

3. You could use the function `sample` for example. Look at `?sample` to find out more.

3. fill in your results into [this shared spreadsheet](https://docs.google.com/spreadsheets/d/118NlPUQjd13XodX7IGri8J-oLgkObdCtDEFri65tWmo/edit?usp=sharing)!

] 


```r
sample(promotions$gender, replace = FALSE) # Note: create a new google csv file
```



---

# Sampling Variation in Reshuffling

.pull-left[
&lt;img src="hypothesis_files/figure-html/unnamed-chunk-10-1.svg" style="display: block; margin: auto;" /&gt;
]

.pull-right[
* This distribution was created in our **hypothetical** scenario: no discrimination.

* We see how sampling variation affects the difference in promotion rates.

* The red line denotes the *observed difference* in the **real world** (29.2%).

* Now: How *likely* is it that the red line is part of this **hypothetical** distribution?
]

---

# Recap: Permutation vs Bootstrap

.pull-left[
* We just did a **permutation test**. We randomly reshuffled and checked if it makes a difference.

* Again Resampling: boostrapping is **with** replacment, permutation is **without**.

* Bootstrapping: we put the paper slips **back** after recording them.

* Permutation: we took card after card from our deck (*without* putting it back!)
]

--

.pull-right[

* We observed the estimate `\(\hat{p}_m - \hat{p}_f = 29.2\%\)` in the real world.

* We *tested* whether in a hypothetical universe with no discrimination, `\(29.2\%\)` *likely* to occur.

* We concluded *rather not*. We tended to **reject** that hypothesis.

* The real question was: is `\(29.2\%\)` **really** different from zero? What is the role of sampling variation? 
]


---
layout: false
class: title-slide-section-red, middle

# Hypothesis Testing Setup



---
layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---

# Hypothesis Test Notation and Definitions

.pull-left[
* In Hypothesis testing we compare two **competing hypothesis**. 
    * In our example:
        `$$\begin{align}H_0:&amp; p_m - p_f = 0\\H_A:&amp; p_m - p_f &gt; 0\end{align}$$`
    * `\(H_0\)` stands for the **null hypothesis**, where *no effect* is observed. That's our hypothetical world from above.

* `\(H_A\)` or `\(H_1\)` is the **alternative** hypothesis. Here, we have a *one-sided* alternative, saying that `\(p_m &gt; p_f\)`, ie women are discriminated against. The *two-sided* formulation is just `\(H_A: p_m - p_f \neq 0\)`

]

--

.pull-right[

* A **test statistic** is a summary statistic which we use to summarise a certain aspect of our sample. Here: `\(\hat{p}_m - \hat{p}_f\)`

* The *observed test statistic* is the number we get from our real world sample: `\(\hat{p}_m - \hat{p}_f = 29\%\)`

* The **null distribution** is the sampling distribution of our test statistic, assuming the Null hypothesis is **true**. That's our hypothetical world without discrimination.

* We have seen such a null distribution just above:
]

---

# Null Distribution

.left-wide[
&lt;img src="hypothesis_files/figure-html/unnamed-chunk-11-1.svg" style="display: block; margin: auto;" /&gt;
]

.right-thin[
* This **is** the sampling distribution of `\(\hat{p}_m - \hat{p}_f\)`, assuming `\(H_0\)` is true.

* The red line is the *observed* test statistic.
]

---

# P-Value and Significance Level `\(\alpha\)`

.pull-left[
* The **p-value** is the probability of observing a test statistic *more extreme* than the one we obtained, assuming `\(H_0\)` is true. 🤔

* How *strong* a piece of evidence is it to observe `\(\hat{p}_m - \hat{p}_f=29\%\)` in a world where `\(p_m - p_f=0\)` is assumed true? Very strong? Not so strong?

* How many samples did we obtain that had a difference *greater* than 29%? Many, or not so many?

* The p-value quantifies this by measuring the probability to the right of the red line in the previous plot.
]



--

.pull-right[
* The **significance level** `\(\alpha\)` is a *cutoff* on the p-value.

* We choose it *before* conducting our hypothesis test. It's common to assume `\(\alpha = 5\%\)`.

* If the p-value falls below the cutoff `\(\alpha\)`, we **reject** the null hypothesis on the grounds that *what we observe is too unlikely to happen* under the Null.

* Small p-value: The red line is *too far* from the center of the Null distribution. Observing the red line would have happened with very small probability only. 

]

---
layout: false
class: title-slide-section-red, middle

# Conducting Hypothesis Tests



---
layout: true

&lt;div class="my-footer"&gt;&lt;img src="../img/logo/ScPo-shield.png" style="height: 60px;"/&gt;&lt;/div&gt; 

---
background-image: url(../img/photos/ht.png)
background-size: 800px
background-position: 60% 60%

# Testing with `infer`


---

# `infer` Testing Pipeline

.pull-left[

* Here we follow closely the [infer workflow](https://moderndive.com/9-hypothesis-testing.html#infer-workflow-ht) given in moderndive.

* We augment our previous pipeline with the `hypothesize` function, defining the type of null hypothesis.

* Also, we give a `formula` to `specify()` this time, instead of only a variable name as before.

* We create the Null Distribution by *reshuffling* (deck of cards), and *not* by *resampling* (pennies).
]

&lt;!-- deck of cards and pennies are examples in Chapter 8 of moderndrive "https://moderndive.com/9-hypothesis-testing.html#infer-workflow-ht") --&gt;

--

.pull-right[

```r
null_distribution &lt;- promotions %&gt;% 
  # takes formula, defines success
  specify(formula = decision ~ gender,
          success = "promoted") %&gt;% 
  # decisions are independent of gender
  hypothesize(null = "independence") %&gt;% 
  # generate 1000 reshufflings of data
  generate(reps = 1000, type = "permute") %&gt;% 
  # compute p_m - p_f from each reshuffle
  calculate(stat = "diff in props",
            order = c("male", "female"))
null_distribution
```

```
## # A tibble: 1,000 x 2
##    replicate    stat
##        &lt;int&gt;   &lt;dbl&gt;
##  1         1 -0.0417
##  2         2 -0.0417
##  3         3  0.0417
##  4         4 -0.208 
##  5         5 -0.208 
##  6         6  0.0417
##  7         7 -0.125 
##  8         8  0.208 
##  9         9  0.125 
## 10        10 -0.0417
## # … with 990 more rows
```
]

---

# Back to Reality: What did we *Observe*?

.pull-left[
* We computed `\(\hat{p}_m - \hat{p}_f\)` from our *real-world* sample before.



```r
obs_diff_prop &lt;- promotions %&gt;% 
  specify(decision ~ gender, success = "promoted") %&gt;% 
  calculate(stat = "diff in props", order = c("male", "female"))
obs_diff_prop
```

```
## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1 0.292
```
]

.pull-right[
* How does that observed statistic compare the distribution of **this** test statistic, assuming that `\(H_0\)` is true?

* We **created** that distribution on the previous slide: `null_distribution`.

* Let's confront `null_distribution` with `obs_diff_prop`, and let's compute the p-value!
]

---

# Visualize the Null

.left-wide[

```r
visualize(null_distribution, bins = 10)
```

&lt;img src="hypothesis_files/figure-html/unnamed-chunk-15-1.svg" style="display: block; margin: auto;" /&gt;
]

.right-thin[
* This is the distribution of `\(\hat{p}_m - \hat{p}_f\)` under `\(H_0\)`.

* No Discrimination in that world.
]

---

# Visualize the P-value

.pull-left[

```r
visualize(null_distribution, bins = 10) + 
  shade_p_value(obs_stat = obs_diff_prop,
                direction = "right")
```

&lt;img src="hypothesis_files/figure-html/unnamed-chunk-16-1.svg" style="display: block; margin: auto;" /&gt;
]

.pull-right[
* `shade_p_value` adds the p-value based on `obs_diff_prop`, i.e 0.29.

* `direction = "right"` represents our one-sided alternative `\(H_A:p_m - p_f &gt; 0\)`

* *more extreme* means *bigger difference* here, hence *more to the right*.

* If `\(H_A:p_m - p_f &lt; 0\)`, we'd set `direction = "left"`

* The red area **is the p-value**!

* Is that a *big* or a *small* area?
]

---

# Obtaining the p-value and Deciding to Reject

.pull-left[
* Obtain the precise p-value with
    
    ```r
    p_value &lt;- null_distribution %&gt;% 
      get_p_value(obs_stat = obs_diff_prop, direction = "right")
    p_value
    ```
    
    ```
    ## # A tibble: 1 x 1
    ##   p_value
    ##     &lt;dbl&gt;
    ## 1   0.019
    ```
    
* So, the probability of observing a 29% difference in a world with no discrimination is only 1.9%. That probability is due to sampling variation.
]

--

.pull-right[
* Suppose we had set `\(\alpha = 0.001 = 0.1\%\)`

* Given that the p-value is *greater* than `\(\alpha\)`, 
    * i.e. 1.9% &gt; 0.1%,
    * we would **fail to reject** the null `\(H_0:p_m - p_f = 0\)`. 

* The p-value was not sufficiently small to convince us in this case.

* What would have happened, had we set cutoff `\(\alpha = 0.05 = 5\%\)` instead?

]

---

# Testing Errors

.pull-left[
* Working with probabilities implies that sometimes, we make an error.

* 29% may be *unlikely* under `\(H_0\)`, but that doesn't mean it's *impossible* to occur.

* So, it may happen that we sometimes reject `\(H_0\)`, when in fact it was true.

]

--

.pull-right[
* This is similar to a verdict reach in a court trial:

![:scale 100%](../img/photos/gt_error_table.png)

* In fact, in hypothesis testing:

![:scale 100%](../img/photos/gt_error_table_ht.png)

]

---

# Type I and Type II Errors

.pull-left[
* So, there are even two types of errors to make! 😲

* Type I: We convict an innocent person. We Reject a *true* Null.

* Type II: We *fail* to convict a criminal. We *fail* to reject a *wrong* Null.

* We **choose** the frequency of a Type I error by setting `\(\alpha\)`, called the **significance level**.
]

--

.pull-right[
* The probability of committing a type II error is called `\(\beta\)`. The value `\(1-\beta\)`, i.e. the prob. of *not* making such an error, is called the **power** of a hypothesis test.

* Ideally, `\(\alpha = \beta = 0\)`. However, with random sampling this is impossible. Also, both errors are inversely related. (see next slide)

* So, typically we fix `\(\alpha\)` and try to maximize the power of the test. 

* Given a certain frequency of convicting an innocent person, we try to make sure we convict as many true criminals as possible.
]

---

# Type I and II Errors are Inversely related

.left-wide[
![](../img/photos/power.png)
]

.right-thin[
* `\(\hat{\theta}\)` is *some* test statistic.

* `\(f(\hat{\theta}|\theta_0)\)` and `\(f(\hat{\theta}|\theta_A)\)` are Null and Alternative distributions.

* Changing `\(\alpha\)` moves critical value `\(\hat{\theta}_c\)`.

* This example is fully worked out [here](https://scpoecon.github.io/ScPoEconometrics/images/hypothesis.pdf) by Florian Oswald
]



---

class: title-slide-final, middle

# THANKS

To the amazing [moderndive](https://moderndive.com/) team!

---

class: title-slide-final, middle
background-image: url(../img/logo/ScPo-econ.png)
background-size: 250px
background-position: 9% 19%

# END




|                                                                                                            |                                   |
| :--------------------------------------------------------------------------------------------------------- | :-------------------------------- |
| &lt;a href="mailto:michele.fioretti@sciencespo.fr"&gt;.ScPored[&lt;i class="fa fa-paper-plane fa-fw"&gt;&lt;/i&gt;]               | michele.fioretti@sciencespo.fr       |
| &lt;a href="https://github.com/michelefioretti/ScPoEconometrics-Slides"&gt;.ScPored[&lt;i class="fa fa-link fa-fw"&gt;&lt;/i&gt;] | Slides |
| &lt;a href="https://michelefioretti.github.io/ScPoEconometrics/"&gt;.ScPored[&lt;i class="fa fa-link fa-fw"&gt;&lt;/i&gt;] | Book |
| &lt;a href="http://twitter.com/ScPoEcon"&gt;.ScPored[&lt;i class="fa fa-twitter fa-fw"&gt;&lt;/i&gt;]                          | @ScPoEcon                         |
| &lt;a href="http://github.com/ScPoEcon"&gt;.ScPored[&lt;i class="fa fa-github fa-fw"&gt;&lt;/i&gt;]                          | @ScPoEcon                       |
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="../js/ru_xaringan.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
